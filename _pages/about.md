---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<!-- {% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %} -->

<span class='anchor' id='about-me'></span>

Hi~, I am Xin Li [É•ÉªnË‰ liË‡] (æé‘«). My research interest includes natrual language processing, large language model, autonomous agent. I have published several papers at the top international AI Conferences / Journals with total <a href="https://scholar.google.com/citations?user=pHPTHHwAAAAJ"><img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Flixin4sky%2Flixin4sky.github.io%40main%2Fresults%2Fgs_data_shieldsio.json&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>. If you are interested in my work or potential collaboration, please feel free to reach out to me at lixin4sky[at]gmail.com.(please replace [at] with @).

# ğŸ”¥ News
- *2024.09*: &nbsp;ğŸ‰ğŸ‰ My first paper is accepted by NeurIPS 2024.

- *2024.09*: &nbsp;ğŸ‰ğŸ‰ I became a Ph.D. Student at Beijing University of Posts and Telecommunications, supervised by Prof. Cheng Yang.


# ğŸ“– Educations
- *2024.09 - Present*, Doctoral student at School of Computer Science, Beijing University of Posts and Telecommunications (BUPT), supervised by Prof. [Cheng Yang(æ¨æˆ)(BUPT)](https://scholar.google.com/citations?user=OlLjVUcAAAAJ), advised by Prof. [Chuan Shi(çŸ³å·)(BUPT)](https://scholar.google.com/citations?user=tUq_v90AAAAJ) and Prof. [Zhiyuan Liu(åˆ˜çŸ¥è¿œ)(THU)](https://scholar.google.com/citations?user=dT0v5u0AAAAJ).
- *2020.09 - 2024.06*, Undergraduate, China University of Petroleum (Beijing) at Karamay.

# ğŸ’» Internships
- *2024.02 - Present*, [THUNLP](https://nlp.csai.tsinghua.edu.cn), advised by Dr. [Weize Chen(é™ˆæšæ³½)](https://scholar.google.com/citations?hl=en&user=0CoGHtIAAAAJ) and Dr. [Chen Qian(é’±å¿±)](https://scholar.google.com/citations?user=Rnsawl0AAAAJ), Beijing.

# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2024</div><img src='../images/papers/prograph_pipeline2.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1"> -->

[(ProGraph) Can Large Language Models Analyze Graphs like Professionals? A Benchmark, Datasets and Models](https://arxiv.org/abs/2409.19667)

**Xin Li\***, Weize Chen\*, Qizhi Chu, Haopeng Li, Zhaojun Sun, Ran Li, Chen Qian, Yiwei Wei, Zhiyuan Liu, Chuan Shi, Maosong Sun, Cheng Yang<sup>â€ </sup>

<!-- [**Source Code**](https://github.com/BUPT-GAMMA/ProGraph) -->

[![](https://img.shields.io/github/stars/BUPT-GAMMA/GraphTeam?style=social&label=Code+Stars)](https://github.com/BUPT-GAMMA/GraphTeam)

<a href='https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pHPTHHwAAAAJ&citation_for_view=pHPTHHwAAAAJ:u-x6o8ySG0sC'><img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Flixin4sky%2Flixin4sky.github.io%2Fmain%2Fresults%2Fall_pubs%2Fu-x6o8ySG0sC.json&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>

[**Models and Datasets**](https://huggingface.co/lixin4sky/ProGraph)

</div></div>

## âŒ›ï¸ Preprints

<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">arxiv preprint</div><img src='../images/papers/graphteam_figure.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1"> -->

<!-- <div class='paper-box'><div class='paper-box-image'>
<video controls width="100%">
  <source src="videos/graphteam/demo1.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>
<div><div class="video-badge">arxiv preprint</div></div>
</div>
<div class='paper-box-text' markdown="1"> -->

<div class='paper-box'>
  <div class='paper-box-image'>
    <video 
      controls 
      width="100%" 
      poster="images/papers/graphteam_figure.png"
      playsinline 
      preload="metadata"
    >
      <source src="videos/graphteam/demo1.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
    <div><div class="video-badge">arxiv preprint</div></div>
  </div>
  <div class='paper-box-text' markdown="1">

<!-- </div></div> -->

[GraphTeam: Facilitating Large Language Model-based Graph Analysis via Multi-Agent Collaboration](https://arxiv.org/abs/2410.18032)

**Xin Li\***, Qizhi Chu\*, Yubin Chen\*, Yang Liu, Yaoqi Liu, Zekai Yu, Weize Chen, Chen Qian, Chuan Shi, Cheng Yang<sup>â€ </sup>

<!-- [**Project**](https://github.com/BUPT-GAMMA/GraphTeam) -->

[![](https://img.shields.io/github/stars/BUPT-GAMMA/GraphTeam?style=social&label=Code+Stars)](https://github.com/BUPT-GAMMA/GraphTeam)

<!-- ä¸‹é¢éœ€è¦ä¿®æ”¹æˆè‡ªå·±çš„å†…å®¹ -->

<a href='https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pHPTHHwAAAAJ&citation_for_view=pHPTHHwAAAAJ:d1gkVwhDpl0C'><img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Flixin4sky%2Flixin4sky.github.io%2Fmain%2Fresults%2Fall_pubs%2Fd1gkVwhDpl0C.json&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>



[**Demo**](http://112.124.25.134/gt/): **You can play it!**

</div></div>

- <span class="conference-badge">arxiv preprint</span> 
[Scalable autoregressive image generation with mamba](https://arxiv.org/abs/2408.12245)
Haopeng Li, Jinyue Yang, Kexin Wang, Xuerui Qiu, Yuhong Chou, Xin Li, Guoqi Li   
<!-- [**Source Code**](https://github.com/hp-l33/AiM) -->
[![](https://img.shields.io/github/stars/hp-l33/AiM?style=social&label=Code+Stars)](https://github.com/hp-l33/AiM)
<a href='https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pHPTHHwAAAAJ&citation_for_view=pHPTHHwAAAAJ:u5HHmVD_uO8C'><img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Flixin4sky%2Flixin4sky.github.io%2Fmain%2Fresults%2Fall_pubs%2Fu5HHmVD_uO8C.json&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>


# ğŸ– Honors and Awards
- *2023.10* National Scholarship(Undergraduate)(Top 1%)
- *2021.10* National Scholarship(Undergraduate)(Top 1%)

# ğŸ“‘ Academic Services

- Reviewer for Conferences: NeurIPS 2024, WWW 2025.


<!-- # ğŸ’¬ Invited Talks -->


